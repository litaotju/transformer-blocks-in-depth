{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Export Tips"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use dynamic_axes to keep the \"Shape\" op and prevent shape inline\n",
    "\n",
    "When not using dynamic_axes, the \"Shape\" op will be removed, and the shape of the input tensor will be hard-coded in the exported model. For a model which needs to support dynamic shapes in the inference time, this is not what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.shape[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following export function does not use the dynamic_axes argument, so the \"Shape\" op is removed. \n",
    "And the `x.shape[-1]` is exported as the evaluated constant value given the input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph():\n",
      "  %1 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/Constant\"](), scope: __main__.Model:: # /tmp/ipykernel_673838/427168263.py:11:0\n",
      "  return (%1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    Model(),\n",
    "    torch.ones(12,8),\n",
    "    \"static_shape.onnx\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following export function uses the dynamic_axes argument, so the \"Shape\" op is kept.\n",
    "The onnx graph looks like this:\n",
    "\n",
    "![onnx graph of shape](./media/torch_dynamic_shape.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(*, *, strides=[8, 1], requires_grad=0, device=cpu)):\n",
      "  %/Shape_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape\"](%input), scope: __main__.Model:: # /tmp/ipykernel_673838/1291048605.py:12:0\n",
      "  %/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant\"](), scope: __main__.Model:: # /tmp/ipykernel_673838/1291048605.py:12:0\n",
      "  %3 : Long(requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather\"](%/Shape_output_0, %/Constant_output_0), scope: __main__.Model:: # /tmp/ipykernel_673838/1291048605.py:12:0\n",
      "  return (%3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.onnx.export(\n",
    "    Model(),\n",
    "    torch.ones(12,8),\n",
    "    \"dynamic_shape.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the torch.Tensor.size() function to get some extent in certain dims will result in different ONNX ops.\n",
    "\n",
    "torch.Tensor.size() will result in a \"Shape -> Slice -> Squeeze\" pattern, like the following graph:\n",
    "\n",
    "![onnx graph of size](./media/torch_dynamic_shape_size.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(*, *, strides=[8, 1], requires_grad=0, device=cpu)):\n",
      "  %/Shape_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape\"](%input), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant\"](), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_1\"](), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/Constant_2\"](), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/Slice\"](%/Shape_output_0, %/Constant_1_output_0, %/Constant_2_output_0, %/Constant_output_0), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_3\"](), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %7 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/Squeeze\"](%/Slice_output_0, %/Constant_3_output_0), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  return (%7)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ModelUseSize(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.size(-1)\n",
    "\n",
    "torch.onnx.export(\n",
    "    ModelUseSize(),\n",
    "    torch.ones(12,8),\n",
    "    \"dynamic_shape_size.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the torch.Tensor.size() function will be exported as a \"Shape -> Gather\" pattern, like the following graph:\n",
    "\n",
    "![onnx graph dynamic shape gather](./media/torch_dynamic_shape_gather.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(*, *, strides=[8, 1], requires_grad=0, device=cpu)):\n",
      "  %/Shape_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape\"](%input), scope: __main__.ModelUseSize2:: # /tmp/ipykernel_673838/2600646057.py:6:0\n",
      "  %/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant\"](), scope: __main__.ModelUseSize2:: # /tmp/ipykernel_673838/2600646057.py:6:0\n",
      "  %3 : Long(requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather\"](%/Shape_output_0, %/Constant_output_0), scope: __main__.ModelUseSize2:: # /tmp/ipykernel_673838/2600646057.py:6:0\n",
      "  return (%3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ModelUseSize2(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.size(0)\n",
    "\n",
    "torch.onnx.export(\n",
    "    ModelUseSize2(),\n",
    "    torch.ones(12,8),\n",
    "    \"dynamic_shape_gather.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Some common patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gather\n",
    "x : torch.Tensor = torch.ones(12,8,8)\n",
    "\n",
    "y = x[0]  # exported as: Gather op, axis=0, index=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unsqueeze\n",
    "y = x.view(1, 12, 8, 8) # exported as: Unsqueeze op, axes=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0faca9c0a7487b0a8cab6682032d0e1bdce24ee994a5eef8cee33e52fa5fa0cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
