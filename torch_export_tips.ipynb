{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Export Tips"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use dynamic_axes to keep the \"Shape\" op and prevent shape inline\n",
    "\n",
    "When not using dynamic_axes, the \"Shape\" op will be removed, and the shape of the input tensor will be hard-coded in the exported model. For a model which needs to support dynamic shapes in the inference time, this is not what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.shape[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following export function does not use the dynamic_axes argument, so the \"Shape\" op is removed. \n",
    "And the `x.shape[-1]` is exported as the evaluated constant value given the input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph():\n",
      "  %1 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={8}, onnx_name=\"/Constant\"](), scope: __main__.Model:: # /tmp/ipykernel_673838/427168263.py:11:0\n",
      "  return (%1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    Model(),\n",
    "    torch.ones(12,8),\n",
    "    \"static_shape.onnx\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following export function uses the dynamic_axes argument, so the \"Shape\" op is kept.\n",
    "The onnx graph looks like this:\n",
    "\n",
    "![onnx graph of shape](./media/torch_dynamic_shape.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(*, *, strides=[8, 1], requires_grad=0, device=cpu)):\n",
      "  %/Shape_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape\"](%input), scope: __main__.Model:: # /tmp/ipykernel_673838/1291048605.py:12:0\n",
      "  %/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant\"](), scope: __main__.Model:: # /tmp/ipykernel_673838/1291048605.py:12:0\n",
      "  %3 : Long(requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather\"](%/Shape_output_0, %/Constant_output_0), scope: __main__.Model:: # /tmp/ipykernel_673838/1291048605.py:12:0\n",
      "  return (%3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.onnx.export(\n",
    "    Model(),\n",
    "    torch.ones(12,8),\n",
    "    \"dynamic_shape.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the torch.Tensor.size() function to get some extent in certain dims will result in different ONNX ops.\n",
    "\n",
    "torch.Tensor.size() will result in a \"Shape -> Slice -> Squeeze\" pattern, like the following graph:\n",
    "\n",
    "![onnx graph of size](./media/torch_dynamic_shape_size.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(*, *, strides=[8, 1], requires_grad=0, device=cpu)):\n",
      "  %/Shape_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape\"](%input), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %/Constant_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant\"](), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %/Constant_1_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}, onnx_name=\"/Constant_1\"](), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %/Constant_2_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}, onnx_name=\"/Constant_2\"](), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %/Slice_output_0 : Long(1, strides=[1], device=cpu) = onnx::Slice[onnx_name=\"/Slice\"](%/Shape_output_0, %/Constant_1_output_0, %/Constant_2_output_0, %/Constant_output_0), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %/Constant_3_output_0 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant_3\"](), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  %7 : Long(requires_grad=0, device=cpu) = onnx::Squeeze[onnx_name=\"/Squeeze\"](%/Slice_output_0, %/Constant_3_output_0), scope: __main__.ModelUseSize:: # /tmp/ipykernel_673838/1713131070.py:6:0\n",
      "  return (%7)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ModelUseSize(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.size(-1)\n",
    "\n",
    "torch.onnx.export(\n",
    "    ModelUseSize(),\n",
    "    torch.ones(12,8),\n",
    "    \"dynamic_shape_size.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the torch.Tensor.size() function will be exported as a \"Shape -> Gather\" pattern, like the following graph:\n",
    "\n",
    "![onnx graph dynamic shape gather](./media/torch_dynamic_shape_gather.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(*, *, strides=[8, 1], requires_grad=0, device=cpu)):\n",
      "  %/Shape_output_0 : Long(2, strides=[1], device=cpu) = onnx::Shape[onnx_name=\"/Shape\"](%input), scope: __main__.ModelUseSize2:: # /tmp/ipykernel_673838/2600646057.py:6:0\n",
      "  %/Constant_output_0 : Long(device=cpu) = onnx::Constant[value={0}, onnx_name=\"/Constant\"](), scope: __main__.ModelUseSize2:: # /tmp/ipykernel_673838/2600646057.py:6:0\n",
      "  %3 : Long(requires_grad=0, device=cpu) = onnx::Gather[axis=0, onnx_name=\"/Gather\"](%/Shape_output_0, %/Constant_output_0), scope: __main__.ModelUseSize2:: # /tmp/ipykernel_673838/2600646057.py:6:0\n",
      "  return (%3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ModelUseSize2(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.size(0)\n",
    "\n",
    "torch.onnx.export(\n",
    "    ModelUseSize2(),\n",
    "    torch.ones(12,8),\n",
    "    \"dynamic_shape_gather.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\", 1: \"seq_len\"},\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Some common patterns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "## Gather\n",
    "x : torch.Tensor = torch.ones(12,8,8)\n",
    "\n",
    "y = x[0]  # exported as: Gather op, axis=0, index=0\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "## Unsqueeze\n",
    "y = x.view(1, 12, 8, 8) # exported as: Unsqueeze op, axes=[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(12, 8, 8, strides=[64, 8, 1], requires_grad=0, device=cpu),\n",
      "      %weight : Float(8, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bias : Float(8, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/ReduceMean_output_0 : Float(12, 8, 1, strides=[8, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/ReduceMean\"](%input), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  %/Sub_output_0 : Float(12, 8, 8, strides=[64, 8, 1], device=cpu) = onnx::Sub[onnx_name=\"/Sub\"](%input, %/ReduceMean_output_0), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  %/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}, onnx_name=\"/Constant\"](), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  %/Pow_output_0 : Float(12, 8, 8, strides=[64, 8, 1], device=cpu) = onnx::Pow[onnx_name=\"/Pow\"](%/Sub_output_0, %/Constant_output_0), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  %/ReduceMean_1_output_0 : Float(12, 8, 1, strides=[8, 1, 1], device=cpu) = onnx::ReduceMean[axes=[-1], onnx_name=\"/ReduceMean_1\"](%/Pow_output_0), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  %/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}, onnx_name=\"/Constant_1\"](), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  %/Add_output_0 : Float(12, 8, 1, strides=[8, 1, 1], device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/ReduceMean_1_output_0, %/Constant_1_output_0), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  %/Sqrt_output_0 : Float(12, 8, 1, strides=[8, 1, 1], device=cpu) = onnx::Sqrt[onnx_name=\"/Sqrt\"](%/Add_output_0), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  %/Div_output_0 : Float(12, 8, 8, strides=[64, 8, 1], device=cpu) = onnx::Div[onnx_name=\"/Div\"](%/Sub_output_0, %/Sqrt_output_0), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  %/Mul_output_0 : Float(12, 8, 8, strides=[64, 8, 1], device=cpu) = onnx::Mul[onnx_name=\"/Mul\"](%/Div_output_0, %weight), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  %13 : Float(12, 8, 8, strides=[64, 8, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/Add_1\"](%/Mul_output_0, %bias), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  return (%13)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## LayerNorm\n",
    "# LayerNorm before opset 17 is exported as a combination of ops\n",
    "torch.onnx.export(\n",
    "    nn.LayerNorm(8),\n",
    "    torch.ones(12,8,8),\n",
    "    \"layer_norm_opset_pre17.onnx\",\n",
    "    verbose=True,\n",
    "    opset_version=16\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![layer norm opset 16](./media/layer-norm-onnx.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(12, 8, 8, strides=[64, 8, 1], requires_grad=0, device=cpu),\n",
      "      %weight : Float(8, strides=[1], requires_grad=1, device=cpu),\n",
      "      %bias : Float(8, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %3 : Float(12, 8, 8, strides=[64, 8, 1], requires_grad=1, device=cpu) = onnx::LayerNormalization[axis=-1, epsilon=1.0000000000000001e-05, onnx_name=\"/LayerNormalization\"](%input, %weight, %bias), scope: torch.nn.modules.normalization.LayerNorm:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/functional.py:2513:0\n",
      "  return (%3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LayerNorm after opset 17 is exported as a single op\n",
    "torch.onnx.export(\n",
    "    nn.LayerNorm(8),\n",
    "    torch.ones(12,8,8),\n",
    "    \"layer_norm_opset17.onnx\",\n",
    "    verbose=True,\n",
    "    opset_version=17\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%onnx::Div_0 : Float(12, 8, strides=[8, 1], requires_grad=0, device=cpu)):\n",
      "  %/Constant_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}, onnx_name=\"/Constant\"](), scope: torch.nn.modules.activation.GELU:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:684:0\n",
      "  %/Div_output_0 : Float(12, 8, strides=[8, 1], device=cpu) = onnx::Div[onnx_name=\"/Div\"](%onnx::Div_0, %/Constant_output_0), scope: torch.nn.modules.activation.GELU:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:684:0\n",
      "  %/Erf_output_0 : Float(12, 8, strides=[8, 1], device=cpu) = onnx::Erf[onnx_name=\"/Erf\"](%/Div_output_0), scope: torch.nn.modules.activation.GELU:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:684:0\n",
      "  %/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}, onnx_name=\"/Constant_1\"](), scope: torch.nn.modules.activation.GELU:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:684:0\n",
      "  %/Add_output_0 : Float(12, 8, strides=[8, 1], device=cpu) = onnx::Add[onnx_name=\"/Add\"](%/Erf_output_0, %/Constant_1_output_0), scope: torch.nn.modules.activation.GELU:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:684:0\n",
      "  %/Mul_output_0 : Float(12, 8, strides=[8, 1], device=cpu) = onnx::Mul[onnx_name=\"/Mul\"](%onnx::Div_0, %/Add_output_0), scope: torch.nn.modules.activation.GELU:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:684:0\n",
      "  %/Constant_2_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}, onnx_name=\"/Constant_2\"](), scope: torch.nn.modules.activation.GELU:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:684:0\n",
      "  %8 : Float(12, 8, strides=[8, 1], requires_grad=0, device=cpu) = onnx::Mul[onnx_name=\"/Mul_1\"](%/Mul_output_0, %/Constant_2_output_0), scope: torch.nn.modules.activation.GELU:: # /home/litao/workspace/tops/venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:684:0\n",
      "  return (%8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Gelu: div -> erf -> add -> mul -> mul\n",
    "torch.onnx.export(\n",
    "    nn.GELU(),\n",
    "    torch.ones(12,8),\n",
    "    \"gelu.onnx\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gelu onnx](./media/gelu-onnx.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0faca9c0a7487b0a8cab6682032d0e1bdce24ee994a5eef8cee33e52fa5fa0cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
